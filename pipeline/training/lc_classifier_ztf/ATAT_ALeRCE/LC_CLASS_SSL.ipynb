{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from src.layers.classifiers import TokenClassifier, MixedClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    \"AGN\": 0,\n",
    "    \"QSO\": 1,\n",
    "    \"EA\": 2,\n",
    "    \"YSO\": 3,\n",
    "    \"SNIa\": 4,\n",
    "    \"CV/Nova\": 5,\n",
    "    \"RRLc\": 6,\n",
    "    \"RSCVn\": 7,\n",
    "    \"Blazar\": 8,\n",
    "    \"SNII\": 9,\n",
    "    \"EB/EW\": 10,\n",
    "    \"LPV\": 11,\n",
    "    \"CEP\": 12,\n",
    "    \"RRLab\": 13,\n",
    "    \"Periodic-Other\": 14,\n",
    "    \"DSCT\": 15,\n",
    "    \"SNIbc\": 16,\n",
    "    \"SLSN\": 17,\n",
    "    \"TDE\": 18,\n",
    "    \"SNIIb\": 19,\n",
    "    \"SNIIn\": 20,\n",
    "    \"Microlensing\": 21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/cosine-four-trans-v0/args.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = '/home/mdelafuente/'#sys.argv[2]\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "abs_path = '//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/cosine-four-trans-v0/'\n",
    "path_args = glob.glob(f\"{abs_path}*args*\")[0]\n",
    "print(path_args)\n",
    "import yaml\n",
    "with open(path_args, 'r') as file:\n",
    "    args = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lc': {'input_size': 1, 'embedding_size': 192, 'embedding_size_sub': 384, 'num_heads': 4, 'num_encoders': 3, 'Tmax': 1500.0, 'num_harmonics': 4, 'pe_type': 'tm', 'encoder_type': 'Linear', 'max_pool_kernel': 5, 'cnn_kernel': 5, 'num_bands': 2}, 'ft': {'embedding_size': 128, 'embedding_size_sub': 256, 'num_heads': 4, 'num_encoders': 3, 'encoder_type': 'Linear', 'length_size': 0, 'list_time_to_eval': None}, 'general': {'experiment_type': 'lc', 'experiment_name': 'cosine-four-trans-v0', 'name_dataset': 'ztf_ff', 'data_root': '/home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/data/datasets/h5file/', 'use_lightcurves': True, 'use_lightcurves_err': False, 'use_metadata': False, 'use_features': False, 'use_sampler': 0, 'batch_size': 256, 'num_epochs': 100, 'patience': 10, 'lr': 0.001, 'use_cosine_decay': False, 'use_gradient_clipping': False, 'use_mask_detection': False, 'use_time_nondetection': False, 'force_online_opt': False, 'online_opt_tt': False, 'use_QT': False, 'load_pretrained_model': False, 'src_checkpoint': '.', 'use_augmented_dataset': False, 'change_clf': False, 'num_classes': 22}}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models\n",
      "Loading checkpoints\n",
      "//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/cosine-four-trans-v0/my_best_checkpoint-step=3529.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Initializing models') \n",
    "from src.layers.cATAT import LightCurveClassifier, LightCurveTransformer\n",
    "model = LightCurveTransformer(**args['lc']) \n",
    "\n",
    "\n",
    "print('Loading checkpoints')\n",
    "checkpoint_path_clip = glob.glob(\n",
    "    f\"{abs_path}*my_best_checkpoint*\"\n",
    ") \n",
    "print(checkpoint_path_clip[-1])\n",
    "checkpoint_clip = torch.load(checkpoint_path_clip[-1], map_location=torch.device('cuda:2'))\n",
    "od_atat = OrderedDict() \n",
    "\n",
    "for key in checkpoint_clip[\"state_dict\"].keys(): \n",
    "        #print(key)\n",
    "        \n",
    "    if 'project' in key:\n",
    "        continue\n",
    "    else:\n",
    "        od_atat[key.replace(\"model.transformer.\", \"\")] = checkpoint_clip[\"state_dict\"][key]\n",
    "\n",
    "model.load_state_dict(od_atat,strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWARGS\n",
      "{'experiment_type': 'lc', 'experiment_name': 'cosine-four-trans-v0', 'name_dataset': 'ztf_ff', 'use_lightcurves': True, 'use_lightcurves_err': False, 'use_metadata': False, 'use_features': False, 'use_sampler': False, 'num_epochs': 100, 'patience': 10, 'lr': 0.001, 'use_cosine_decay': False, 'use_gradient_clipping': False, 'use_mask_detection': False, 'use_time_nondetection': False, 'force_online_opt': False, 'online_opt_tt': False, 'use_QT': False, 'load_pretrained_model': False, 'src_checkpoint': '.', 'use_augmented_dataset': False, 'change_clf': False, 'num_classes': 22}\n",
      "using set validation total of idx : 40698,                 use_lightcurves True, use_metadata False, use_features False,                     use MTA False\n",
      "list_time_to_eval:  [16, 32, 64, 128, 256, 512, 1024, 2048]\n",
      "NOT USING SAMPLER\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "from src.data.modules.LitData  import LitData\n",
    "args['general']['data_root'] = 'data/datasets/ZTF_ff/final/LC_MD_FEAT_240627_windows_200_12'\n",
    "args['general']['data_root'] = 'data/datasets/ZTF_ff/final/LC_MD_FEAT_240627_windows_200_12'\n",
    "args['general']['use_sampler'] = False\n",
    "pl_datal = LitData(**args['general'])\n",
    "dataloader = pl_datal.val_dataloader() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:22<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "target = None\n",
    "preds_out = None\n",
    "\n",
    "model.eval().to(device = 'cuda:2')  \n",
    "\n",
    "for b1 in tqdm(dataloader):\n",
    "\n",
    "    #print(b1.keys())\n",
    "    b1 = {key:value.to(device = 'cuda:2') for key, value in b1.items()}\n",
    "    t = b1['labels']\n",
    "    del b1['labels']\n",
    "    lc_emb = model(**b1)  \n",
    "    \n",
    "    \n",
    "\n",
    "    preds_out = (\n",
    "        np.concatenate([preds_out, torch.argmax(lc_emb, axis=1).cpu().numpy()])\n",
    "        if preds_out is not None\n",
    "        else torch.argmax(lc_emb, axis=1).cpu().detach().numpy()\n",
    "    )\n",
    "\n",
    "    target = (\n",
    "        np.concatenate([target, t.cpu().detach().numpy()])\n",
    "        if target is not None\n",
    "        else t.cpu().numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22,), (133,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target).shape,np.unique(preds_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.plottinglib import elasticc_confusion_matrix\n",
    "\n",
    "out_metrics_balto = classification_report(\n",
    "    target, results, target_names=list(dict.keys()), output_dict=True\n",
    ")[\"macro avg\"]\n",
    "\n",
    "template_balto = \"\"\n",
    "\n",
    "for key in out_metrics_balto.keys():\n",
    "    template_balto += \" {} : {:.3f} \".format(key.upper(), out_metrics_balto[key])\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "elasticc_confusion_matrix(\n",
    "    y_true=target,\n",
    "    y_pred=results,\n",
    "    classes= np.array(list(dict.keys())),\n",
    "    ax=axes,\n",
    "    normalize=True,\n",
    "    title=f\" FClassifier Results [TEST] \\n\\n {template_balto}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
