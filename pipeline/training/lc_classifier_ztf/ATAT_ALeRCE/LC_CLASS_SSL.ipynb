{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from src.layers.classifiers import TokenClassifier, MixedClassifier\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    \"AGN\": 0,\n",
    "    \"QSO\": 1,\n",
    "    \"EA\": 2,\n",
    "    \"YSO\": 3,\n",
    "    \"SNIa\": 4,\n",
    "    \"CV/Nova\": 5,\n",
    "    \"RRLc\": 6,\n",
    "    \"RSCVn\": 7,\n",
    "    \"Blazar\": 8,\n",
    "    \"SNII\": 9,\n",
    "    \"EB/EW\": 10,\n",
    "    \"LPV\": 11,\n",
    "    \"CEP\": 12,\n",
    "    \"RRLab\": 13,\n",
    "    \"Periodic-Other\": 14,\n",
    "    \"DSCT\": 15,\n",
    "    \"SNIbc\": 16,\n",
    "    \"SLSN\": 17,\n",
    "    \"TDE\": 18,\n",
    "    \"SNIIb\": 19,\n",
    "    \"SNIIn\": 20,\n",
    "    \"Microlensing\": 21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/pretrain/args.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = '/home/mdelafuente/'#sys.argv[2]\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "abs_path = '//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/pretrain/'\n",
    "path_args = glob.glob(f\"{abs_path}*args*\")[0]\n",
    "print(path_args)\n",
    "import yaml\n",
    "with open(path_args, 'r') as file:\n",
    "    args = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models\n",
      "Loading checkpoints\n",
      "//home/mdelafuente/pipeline/pipeline/training/lc_classifier_ztf/ATAT_ALeRCE/results/ZTF_ff/LC/pretrain/my_best_checkpoint-step=36289.ckpt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LightCurveClassifier:\n\tMissing key(s) in state_dict: \"LC.time_encoder.time_encoders.0.alpha_sin\", \"LC.time_encoder.time_encoders.0.alpha_cos\", \"LC.time_encoder.time_encoders.0.beta_sin\", \"LC.time_encoder.time_encoders.0.beta_cos\", \"LC.time_encoder.time_encoders.0.ar\", \"LC.time_encoder.time_encoders.0.linear_proj.0.weight\", \"LC.time_encoder.time_encoders.0.linear_proj.0.bias\", \"LC.time_encoder.time_encoders.1.alpha_sin\", \"LC.time_encoder.time_encoders.1.alpha_cos\", \"LC.time_encoder.time_encoders.1.beta_sin\", \"LC.time_encoder.time_encoders.1.beta_cos\", \"LC.time_encoder.time_encoders.1.ar\", \"LC.time_encoder.time_encoders.1.linear_proj.0.weight\", \"LC.time_encoder.time_encoders.1.linear_proj.0.bias\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.3.bias\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.3.bias\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.3.bias\", \"LC.token_lc.token\", \"classifier_lc.norm.weight\", \"classifier_lc.norm.bias\", \"classifier_lc.net.0.weight\", \"classifier_lc.net.0.bias\", \"classifier_lc.net.3.weight\", \"classifier_lc.net.3.bias\", \"classifier_lc.net.6.weight\", \"classifier_lc.net.6.bias\". \n\tUnexpected key(s) in state_dict: \"transformer.time_encoder.time_encoders.0.alpha_sin\", \"transformer.time_encoder.time_encoders.0.alpha_cos\", \"transformer.time_encoder.time_encoders.0.beta_sin\", \"transformer.time_encoder.time_encoders.0.beta_cos\", \"transformer.time_encoder.time_encoders.0.ar\", \"transformer.time_encoder.time_encoders.0.linear_proj.0.weight\", \"transformer.time_encoder.time_encoders.0.linear_proj.0.bias\", \"transformer.time_encoder.time_encoders.1.alpha_sin\", \"transformer.time_encoder.time_encoders.1.alpha_cos\", \"transformer.time_encoder.time_encoders.1.beta_sin\", \"transformer.time_encoder.time_encoders.1.beta_cos\", \"transformer.time_encoder.time_encoders.1.ar\", \"transformer.time_encoder.time_encoders.1.linear_proj.0.weight\", \"transformer.time_encoder.time_encoders.1.linear_proj.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.3.bias\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.3.bias\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.3.bias\", \"transformer.token_lc.token\", \"project.projection.0.weight\", \"project.projection.0.bias\", \"project.projection.1.weight\", \"project.projection.1.bias\", \"project.projection.3.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m     18\u001b[0m             od_atat[key\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m=\u001b[39m checkpoint_clip[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m][key]\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mod_atat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ATAT/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LightCurveClassifier:\n\tMissing key(s) in state_dict: \"LC.time_encoder.time_encoders.0.alpha_sin\", \"LC.time_encoder.time_encoders.0.alpha_cos\", \"LC.time_encoder.time_encoders.0.beta_sin\", \"LC.time_encoder.time_encoders.0.beta_cos\", \"LC.time_encoder.time_encoders.0.ar\", \"LC.time_encoder.time_encoders.0.linear_proj.0.weight\", \"LC.time_encoder.time_encoders.0.linear_proj.0.bias\", \"LC.time_encoder.time_encoders.1.alpha_sin\", \"LC.time_encoder.time_encoders.1.alpha_cos\", \"LC.time_encoder.time_encoders.1.beta_sin\", \"LC.time_encoder.time_encoders.1.beta_cos\", \"LC.time_encoder.time_encoders.1.ar\", \"LC.time_encoder.time_encoders.1.linear_proj.0.weight\", \"LC.time_encoder.time_encoders.1.linear_proj.0.bias\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.0.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.0.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.0.feed_forward.net.3.bias\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.1.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.1.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.1.feed_forward.net.3.bias\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.0.a_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.0.b_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.1.a_2\", \"LC.transformer_lc.stacked_transformers.2.layer_norm.1.b_2\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.0.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.0.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.1.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.1.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.2.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.linears.2.bias\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.last.weight\", \"LC.transformer_lc.stacked_transformers.2.attn_forward.last.bias\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.0.weight\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.0.bias\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.3.weight\", \"LC.transformer_lc.stacked_transformers.2.feed_forward.net.3.bias\", \"LC.token_lc.token\", \"classifier_lc.norm.weight\", \"classifier_lc.norm.bias\", \"classifier_lc.net.0.weight\", \"classifier_lc.net.0.bias\", \"classifier_lc.net.3.weight\", \"classifier_lc.net.3.bias\", \"classifier_lc.net.6.weight\", \"classifier_lc.net.6.bias\". \n\tUnexpected key(s) in state_dict: \"transformer.time_encoder.time_encoders.0.alpha_sin\", \"transformer.time_encoder.time_encoders.0.alpha_cos\", \"transformer.time_encoder.time_encoders.0.beta_sin\", \"transformer.time_encoder.time_encoders.0.beta_cos\", \"transformer.time_encoder.time_encoders.0.ar\", \"transformer.time_encoder.time_encoders.0.linear_proj.0.weight\", \"transformer.time_encoder.time_encoders.0.linear_proj.0.bias\", \"transformer.time_encoder.time_encoders.1.alpha_sin\", \"transformer.time_encoder.time_encoders.1.alpha_cos\", \"transformer.time_encoder.time_encoders.1.beta_sin\", \"transformer.time_encoder.time_encoders.1.beta_cos\", \"transformer.time_encoder.time_encoders.1.ar\", \"transformer.time_encoder.time_encoders.1.linear_proj.0.weight\", \"transformer.time_encoder.time_encoders.1.linear_proj.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.0.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.0.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.0.feed_forward.net.3.bias\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.1.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.1.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.1.feed_forward.net.3.bias\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.0.a_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.0.b_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.1.a_2\", \"transformer.transformer_lc.stacked_transformers.2.layer_norm.1.b_2\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.0.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.0.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.1.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.1.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.2.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.linears.2.bias\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.last.weight\", \"transformer.transformer_lc.stacked_transformers.2.attn_forward.last.bias\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.0.weight\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.0.bias\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.3.weight\", \"transformer.transformer_lc.stacked_transformers.2.feed_forward.net.3.bias\", \"transformer.token_lc.token\", \"project.projection.0.weight\", \"project.projection.0.bias\", \"project.projection.1.weight\", \"project.projection.1.bias\", \"project.projection.3.weight\". "
     ]
    }
   ],
   "source": [
    "print('Initializing models') \n",
    "from src.layers.cATAT import LightCurveClassifier\n",
    "model = LightCurveClassifier(**args) \n",
    "\n",
    "\n",
    "print('Loading checkpoints')\n",
    "checkpoint_path_clip = glob.glob(\n",
    "    f\"{abs_path}*my_best_checkpoint*\"\n",
    ") \n",
    "print(checkpoint_path_clip[-1])\n",
    "checkpoint_clip = torch.load(checkpoint_path_clip[-1], map_location=torch.device('cuda:2'))\n",
    "od_atat = OrderedDict() \n",
    "\n",
    "for key in checkpoint_clip[\"state_dict\"].keys(): \n",
    "        #print(key)\n",
    "         \n",
    "        if 'model' in key:\n",
    "            od_atat[key.replace(\"model.\", \"\")] = checkpoint_clip[\"state_dict\"][key]\n",
    "\n",
    "model.load_state_dict(od_atat,strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "from src.data.modules.LitData  import LitData\n",
    "args['general']['data_root'] = 'data/datasets/ZTF_ff/final/LC_MD_FEAT_240627_windows_200_12'\n",
    "args['general']['data_root'] = 'data/datasets/ZTF_ff/final/LC_MD_FEAT_240627_windows_200_12'\n",
    "args['general']['use_sampler'] = False\n",
    "pl_datal = LitData(**args['general'])\n",
    "dataloader = pl_datal.val_dataloader() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = None\n",
    "preds_out = None\n",
    "\n",
    "model.eval().to(device = 'cuda:2')  \n",
    "\n",
    "for b1 in tqdm(dataloader):\n",
    "\n",
    "    #print(b1.keys())\n",
    "    b1 = {k: b1[k].float().to(device = 'cuda:2') for k in b1.keys()}\n",
    "\n",
    "    lc_emb = model(**b1)  \n",
    "   \n",
    "    t = b1['labels']\n",
    "\n",
    "\n",
    "    preds_out = (\n",
    "        np.concatenate([preds_out, torch.argmax(lc_emb, axis=1).cpu().numpy()])\n",
    "        if preds_out is not None\n",
    "        else torch.argmax(lc_emb, axis=1).cpu().detach().numpy()\n",
    "    )\n",
    "\n",
    "    target = (\n",
    "        np.concatenate([target, t.cpu().detach().numpy()])\n",
    "        if target is not None\n",
    "        else t.cpu().numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = preds_out\n",
    "classification = classification_report(target, results, target_names=list(dict.keys()),digits = 4)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.plottinglib import elasticc_confusion_matrix\n",
    "\n",
    "out_metrics_balto = classification_report(\n",
    "    target, results, target_names=list(dict.keys()), output_dict=True\n",
    ")[\"macro avg\"]\n",
    "\n",
    "template_balto = \"\"\n",
    "\n",
    "for key in out_metrics_balto.keys():\n",
    "    template_balto += \" {} : {:.3f} \".format(key.upper(), out_metrics_balto[key])\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "elasticc_confusion_matrix(\n",
    "    y_true=target,\n",
    "    y_pred=results,\n",
    "    classes= np.array(list(dict.keys())),\n",
    "    ax=axes,\n",
    "    normalize=True,\n",
    "    title=f\" FClassifier Results [TEST] \\n\\n {template_balto}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
